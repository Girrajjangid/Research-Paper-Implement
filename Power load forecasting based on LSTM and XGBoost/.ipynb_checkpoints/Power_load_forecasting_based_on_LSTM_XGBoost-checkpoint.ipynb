{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power load forecasting Based on LSTM + XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import os\n",
    "import pymysql\n",
    "import requests\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rcParams['figure.figsize'] = 18,6\n",
    "from sqlalchemy import create_engine\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# Importing libraries for RNN's\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, Lambda\n",
    "from tensorflow.keras.layers import ELU, LSTM, Dense, Dropout, Input, Reshape, Flatten, multiply, concatenate, LeakyReLU\n",
    "\n",
    "# Importing libraries for XGboost\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import plot_importance\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "\n",
    "# Used defined classes\n",
    "path = \"C:\\\\Users\\\\GirrajJangid\\\\jupyter notebook\\\\Climate Connect\\\\ServerFiles\\\\BYPL\\\\DayAheads\\\\keras_server\\\\NeuralNets\\\\\"\n",
    "os.chdir(path)\n",
    "from bypl_support_new import *\n",
    "from DBHelper import DbHelper\n",
    "db = DbHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will update the pickle file\n",
    "def update_datasets():\n",
    "    raw_df  = preprocess().fetch_data('bypl_data','train','holidays.csv')\n",
    "    raw_wdf = preprocess().weather('brpl_weather_data', 8, {13:[1]}, 'no')\n",
    "    return \"Pickle updated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(update_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates = date(2020,4,17)\n",
    "\n",
    "df,wdf = raw_df.copy(), raw_wdf.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(data, year, month):\n",
    "    temp = data[data.year.isin(year)]\n",
    "    temp = temp[temp.month.isin(month)]\n",
    "    return temp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df  = preprocess().fetch_data('bypl_data','train','holidays.csv')\n",
    "raw_wdf = preprocess().weather('brpl_weather_data', 8, {13:[1]}, 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in shift_features:\n",
    "    df[i] = df[i].shift(-192)\n",
    "\n",
    "df = df[features].copy()\n",
    "df.dropna(inplace=True)\n",
    "df['target'] = df.load.shift(-192)\n",
    "\n",
    "\n",
    "validation = 15 * 96\n",
    "\n",
    "x_train, y_train   = df[df.target.notna()].iloc[:-validation,1:-1], df[df.target.notna()].iloc[:-validation,-1]\n",
    "x_valid, y_valid   = df[df.target.notna()].iloc[-validation:,1:-1], df[df.target.notna()].iloc[-validation:,-1] \n",
    "x_test = df.iloc[-96:].iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_date:  2019-07-28\n",
      "Yesterday_date:   2019-07-30\n",
      "today_date:       2019-07-31\n",
      "prediction_date:  2019-08-01\n",
      "Weekahead_date:   2019-08-07\n"
     ]
    }
   ],
   "source": [
    "# Change only prediction date\n",
    "prediction_date = date(2019,8,1)\n",
    "\n",
    "today_date      = prediction_date - timedelta(days=1)\n",
    "yesterday_date  = prediction_date - timedelta(days=2)\n",
    "validation_date = prediction_date - timedelta(days=4) \n",
    "weekahead_date = prediction_date + timedelta(days=6)\n",
    "print(\"Validation_date: \",validation_date)\n",
    "print(\"Yesterday_date:  \",yesterday_date)\n",
    "print(\"today_date:      \",today_date)\n",
    "print(\"prediction_date: \",prediction_date)\n",
    "print(\"Weekahead_date:  \",weekahead_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing pickle file for UDM load data...\n",
      "pickle file imported\n",
      "Fetching recent data to check for updates...\n",
      "Load data already updated. Proceeding without any changes to pickled file...\n",
      "Removing holidays...\n",
      "Load data prepared\n",
      "Fetching weather pickle file\n",
      "Fetching weather data from api\n",
      "location 13 data added\n",
      "last date for actual weather data for plant id 13 is 2019-07-30\n",
      "Processing load-weighted weather averages...\n",
      "Adding derivatives...\n",
      "Final derivatives added\n",
      "Weather data transformation complete\n"
     ]
    }
   ],
   "source": [
    "# Pickle file contains all data we need to remove all holidays thats why you have call that function again\n",
    "# and again\n",
    "raw_df  = preprocess().fetch_data('bypl_data','train','holidays.csv', prediction_date)\n",
    "raw_wdf = preprocess().weather('brpl_weather_data', 8, {13:[1]}, 'no', prediction_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>load</th>\n",
       "      <th>tb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-02 00:00:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>642.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-02 00:15:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>636.34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-02 00:30:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>627.52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-02 00:45:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>613.38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-02 01:00:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>599.73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110139</th>\n",
       "      <td>2019-07-30 22:45:00</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1256.18</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110140</th>\n",
       "      <td>2019-07-30 23:00:00</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1262.75</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110141</th>\n",
       "      <td>2019-07-30 23:15:00</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1261.60</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110142</th>\n",
       "      <td>2019-07-30 23:30:00</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1251.29</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110143</th>\n",
       "      <td>2019-07-30 23:45:00</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1230.65</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime        date     load  tb\n",
       "0      2016-04-02 00:00:00  2016-04-02   642.84   1\n",
       "1      2016-04-02 00:15:00  2016-04-02   636.34   2\n",
       "2      2016-04-02 00:30:00  2016-04-02   627.52   3\n",
       "3      2016-04-02 00:45:00  2016-04-02   613.38   4\n",
       "4      2016-04-02 01:00:00  2016-04-02   599.73   5\n",
       "...                    ...         ...      ...  ..\n",
       "110139 2019-07-30 22:45:00  2019-07-30  1256.18  92\n",
       "110140 2019-07-30 23:00:00  2019-07-30  1262.75  93\n",
       "110141 2019-07-30 23:15:00  2019-07-30  1261.60  94\n",
       "110142 2019-07-30 23:30:00  2019-07-30  1251.29  95\n",
       "110143 2019-07-30 23:45:00  2019-07-30  1230.65  96\n",
       "\n",
       "[110144 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is for training purpose\n",
    "df, wdf = raw_df.copy(), raw_wdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding time based features...\n",
      "Adding lags...\n",
      "Adding ewms for load...\n",
      "Adding sine derivatives to time variables...\n",
      "Adding the hourly running mean for load...\n",
      "Merging load and weather databases...\n",
      "Adding final features...\n",
      "Feature engineering completed successfully\n"
     ]
    }
   ],
   "source": [
    "final_df = preprocess().feature_eng(df, wdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>load</th>\n",
       "      <th>tb</th>\n",
       "      <th>dow</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>doy</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>lag1b</th>\n",
       "      <th>lag2b</th>\n",
       "      <th>lag3b</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>load_wm2h</th>\n",
       "      <th>load_wm3h</th>\n",
       "      <th>load_wm5h</th>\n",
       "      <th>load_wm24h</th>\n",
       "      <th>sin_doy</th>\n",
       "      <th>sin_tb</th>\n",
       "      <th>sin_dow</th>\n",
       "      <th>hour_mean</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>humidex</th>\n",
       "      <th>RH</th>\n",
       "      <th>wci</th>\n",
       "      <th>tb_aptemp</th>\n",
       "      <th>load_aptemp</th>\n",
       "      <th>aptemp_mean_6h</th>\n",
       "      <th>aptemp_mean_12h</th>\n",
       "      <th>temperature_ewm</th>\n",
       "      <th>dp_ewm</th>\n",
       "      <th>hm12</th>\n",
       "      <th>wsp_12</th>\n",
       "      <th>cc_12</th>\n",
       "      <th>tb_load</th>\n",
       "      <th>sdtbrm</th>\n",
       "      <th>sdtbrm2</th>\n",
       "      <th>3tbrm</th>\n",
       "      <th>3tbrmw</th>\n",
       "      <th>factor</th>\n",
       "      <th>lag1wm</th>\n",
       "      <th>lag2wm</th>\n",
       "      <th>lag3wm</th>\n",
       "      <th>lag4wm</th>\n",
       "      <th>lag5wm</th>\n",
       "      <th>lag6wm</th>\n",
       "      <th>load_aptemp_ewm6</th>\n",
       "      <th>load_aptemp_ewm12</th>\n",
       "      <th>load_aptemp_ewm24</th>\n",
       "      <th>lagcwm</th>\n",
       "      <th>lag4avg</th>\n",
       "      <th>lag_df</th>\n",
       "      <th>lag_df1</th>\n",
       "      <th>load_wm12h</th>\n",
       "      <th>wt</th>\n",
       "      <th>tm</th>\n",
       "      <th>tm2</th>\n",
       "      <th>tm3</th>\n",
       "      <th>tm4</th>\n",
       "      <th>th</th>\n",
       "      <th>th2</th>\n",
       "      <th>th3</th>\n",
       "      <th>aptemp_lag12h</th>\n",
       "      <th>aptemp_lag1d</th>\n",
       "      <th>humidex_lag12h</th>\n",
       "      <th>humidex_lag1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-02 00:00:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>642.84</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>642.840000</td>\n",
       "      <td>642.840000</td>\n",
       "      <td>642.840000</td>\n",
       "      <td>642.840000</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.065403</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>630.02</td>\n",
       "      <td>27.350</td>\n",
       "      <td>26.9000</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>15.7300</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>31.335686</td>\n",
       "      <td>50.470953</td>\n",
       "      <td>29.153572</td>\n",
       "      <td>27.35</td>\n",
       "      <td>17581.6740</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>15.730000</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>642.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17581.674000</td>\n",
       "      <td>17581.674000</td>\n",
       "      <td>17581.674000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>642.840000</td>\n",
       "      <td>5</td>\n",
       "      <td>107.60</td>\n",
       "      <td>723.610000</td>\n",
       "      <td>748.022500</td>\n",
       "      <td>109.400000</td>\n",
       "      <td>26.9000</td>\n",
       "      <td>723.610000</td>\n",
       "      <td>19465.109000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-02 00:15:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>636.34</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>642.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.183750</td>\n",
       "      <td>639.319167</td>\n",
       "      <td>639.427500</td>\n",
       "      <td>639.556146</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>630.02</td>\n",
       "      <td>27.735</td>\n",
       "      <td>27.3975</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>14.5425</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>31.089340</td>\n",
       "      <td>45.423505</td>\n",
       "      <td>29.618924</td>\n",
       "      <td>55.47</td>\n",
       "      <td>17648.8899</td>\n",
       "      <td>27.550521</td>\n",
       "      <td>27.546510</td>\n",
       "      <td>27.153932</td>\n",
       "      <td>15.123880</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>1.074792</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1272.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17616.682281</td>\n",
       "      <td>17615.982116</td>\n",
       "      <td>17615.632033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.522292</td>\n",
       "      <td>5</td>\n",
       "      <td>109.59</td>\n",
       "      <td>750.623006</td>\n",
       "      <td>758.810236</td>\n",
       "      <td>110.186042</td>\n",
       "      <td>27.3975</td>\n",
       "      <td>750.623006</td>\n",
       "      <td>20565.193814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-02 00:30:00</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>627.52</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>636.34</td>\n",
       "      <td>642.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>634.288601</td>\n",
       "      <td>634.713949</td>\n",
       "      <td>635.055137</td>\n",
       "      <td>635.460226</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>630.02</td>\n",
       "      <td>28.120</td>\n",
       "      <td>27.8950</td>\n",
       "      <td>0.011021</td>\n",
       "      <td>13.3550</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>30.892916</td>\n",
       "      <td>40.855814</td>\n",
       "      <td>30.117798</td>\n",
       "      <td>84.36</td>\n",
       "      <td>17645.8624</td>\n",
       "      <td>27.756377</td>\n",
       "      <td>27.745693</td>\n",
       "      <td>27.411317</td>\n",
       "      <td>14.509519</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>1.312776</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>1882.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17627.230329</td>\n",
       "      <td>17626.360036</td>\n",
       "      <td>17625.919476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>635.353696</td>\n",
       "      <td>5</td>\n",
       "      <td>111.58</td>\n",
       "      <td>778.131025</td>\n",
       "      <td>769.823474</td>\n",
       "      <td>110.982772</td>\n",
       "      <td>27.8950</td>\n",
       "      <td>778.131025</td>\n",
       "      <td>21705.964942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime        date    load  tb  dow  weekend  hour  doy  month  \\\n",
       "0 2016-04-02 00:00:00  2016-04-02  642.84   1    5        0     1   93      4   \n",
       "1 2016-04-02 00:15:00  2016-04-02  636.34   2    5        0     1   93      4   \n",
       "2 2016-04-02 00:30:00  2016-04-02  627.52   3    5        0     1   93      4   \n",
       "\n",
       "   year   lag1b   lag2b  lag3b  lag1  lag2  lag3  lag4  lag5  lag6  \\\n",
       "0  2016     NaN     NaN    NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  2016  642.84     NaN    NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2  2016  636.34  642.84    NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "    load_wm2h   load_wm3h   load_wm5h  load_wm24h   sin_doy    sin_tb  \\\n",
       "0  642.840000  642.840000  642.840000  642.840000  0.999546  0.065403   \n",
       "1  639.183750  639.319167  639.427500  639.556146  0.999546  0.130526   \n",
       "2  634.288601  634.713949  635.055137  635.460226  0.999546  0.195090   \n",
       "\n",
       "    sin_dow  hour_mean  apparent_temperature  temperature  humidity  \\\n",
       "0 -0.974928     630.02                27.350      26.9000  0.012888   \n",
       "1 -0.974928     630.02                27.735      27.3975  0.011922   \n",
       "2 -0.974928     630.02                28.120      27.8950  0.011021   \n",
       "\n",
       "   dew_point  wind_speed  cloud_cover    humidex         RH        wci  \\\n",
       "0    15.7300        0.84       0.0100  31.335686  50.470953  29.153572   \n",
       "1    14.5425        1.30       0.0075  31.089340  45.423505  29.618924   \n",
       "2    13.3550        1.76       0.0050  30.892916  40.855814  30.117798   \n",
       "\n",
       "   tb_aptemp  load_aptemp  aptemp_mean_6h  aptemp_mean_12h  temperature_ewm  \\\n",
       "0      27.35   17581.6740       27.350000        27.350000        26.900000   \n",
       "1      55.47   17648.8899       27.550521        27.546510        27.153932   \n",
       "2      84.36   17645.8624       27.756377        27.745693        27.411317   \n",
       "\n",
       "      dp_ewm      hm12    wsp_12     cc_12  tb_load  sdtbrm  sdtbrm2  3tbrm  \\\n",
       "0  15.730000  0.012888  0.840000  0.010000   642.84     NaN      NaN    NaN   \n",
       "1  15.123880  0.012395  1.074792  0.008724  1272.68     NaN      NaN    NaN   \n",
       "2  14.509519  0.011918  1.312776  0.007431  1882.56     NaN      NaN    NaN   \n",
       "\n",
       "   3tbrmw  factor  lag1wm  lag2wm  lag3wm  lag4wm  lag5wm  lag6wm  \\\n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   load_aptemp_ewm6  load_aptemp_ewm12  load_aptemp_ewm24  lagcwm  lag4avg  \\\n",
       "0      17581.674000       17581.674000       17581.674000     NaN      NaN   \n",
       "1      17616.682281       17615.982116       17615.632033     NaN      NaN   \n",
       "2      17627.230329       17626.360036       17625.919476     NaN      NaN   \n",
       "\n",
       "   lag_df  lag_df1  load_wm12h  wt      tm         tm2         tm3  \\\n",
       "0     NaN      NaN  642.840000   5  107.60  723.610000  748.022500   \n",
       "1     NaN      NaN  639.522292   5  109.59  750.623006  758.810236   \n",
       "2     NaN      NaN  635.353696   5  111.58  778.131025  769.823474   \n",
       "\n",
       "          tm4       th         th2           th3  aptemp_lag12h  aptemp_lag1d  \\\n",
       "0  109.400000  26.9000  723.610000  19465.109000            NaN           NaN   \n",
       "1  110.186042  27.3975  750.623006  20565.193814            NaN           NaN   \n",
       "2  110.982772  27.8950  778.131025  21705.964942            NaN           NaN   \n",
       "\n",
       "   humidex_lag12h  humidex_lag1d  \n",
       "0             NaN            NaN  \n",
       "1             NaN            NaN  \n",
       "2             NaN            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify which features do you want to use in the model\n",
    "features = ['datetime','load','lag1','lag2','lag3','lag5',\n",
    "            'lag4wm', # lag 4th days exponential weight\n",
    "            'hour_mean','sin_doy','dow','tb_aptemp',\n",
    "            'sdtbrm',         # today + 5th day lag average \n",
    "            '3tbrm','3tbrmw', # last 3 days load average\n",
    "            'sdtbrm2',        # today + 6th day lag average\n",
    "            'temperature_ewm','apparent_temperature',\n",
    "            'RH','dew_point',\n",
    "            'aptemp_mean_12h','aptemp_mean_6h','doy','humidex',\n",
    "            'tm','tm2','tm3', 'tm4',   # apparent_temp 12 hour expoentail * month\n",
    "            'load_wm3h','month','year','hour',\n",
    "            'humidity','sin_tb',\n",
    "            'hm12','dp_ewm',\n",
    "            'lagcwm', # last days expoential then average\n",
    "            'load_wm12h','wci','wsp_12','cc_12',\n",
    "            'wind_speed','cloud_cover','temperature',\n",
    "            'wt', # dow * hour\n",
    "            'load_aptemp','load_aptemp_ewm6','load_aptemp_ewm12',\n",
    "            'tb_load']\n",
    "\n",
    "\n",
    "#Specify weather and time based variables to 'shift' them up when running the model as is required\n",
    "shift_features = ['temperature_ewm','dp_ewm','temperature','apparent_temperature','dew_point','RH','aptemp_mean_6h',\\\n",
    "                'aptemp_mean_12h','humidex','dow','tb_aptemp','humidity','doy','month','hm12','wind_speed',\\\n",
    "                'cloud_cover','wsp_12','cc_12','wci','wt','tm','tm2','tm3','tm4']\n",
    "\n",
    "#specify the features you want the model to treat as categorical. Note: This only works with lightgbm\n",
    "categorical_features = ['dow','month','year','hour']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 192\n",
    "df4 = final_df[selected_features]\n",
    "df4['target'] = df4.load.shift(-i) \n",
    "\n",
    "for j in selected_shift_features:\n",
    "    df4[j] = df4[j].shift(-i)\n",
    "\n",
    "df4.dropna(inplace=True)\n",
    "x, y = df4.drop('target',1).copy(), df4[['datetime','target']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x[x['datetime'] < misc().get_date(0) + ' 00:00:00'], y[y['datetime'] < misc().get_date(0) + ' 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['date','datetime'],axis=1)\n",
    "y_train = y_train.drop(['datetime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train.iloc[:-validation*96,].reset_index(drop=True), y_train.iloc[:-validation*96].reset_index(drop=True)\n",
    "x_val, y_val = x_train.iloc[-validation*96:,].reset_index(drop=True), y_train.iloc[-validation*96:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.iloc[:,1:]\n",
    "x_val = x_val.iloc[:,1:]\n",
    "y_train = y_train.iloc[:,1:]\n",
    "y_val = y_val.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = 192\n",
    "df4 = final_df[selected_features]\n",
    "df4['target'] = df4.load.shift(-i) \n",
    "\n",
    "for j in selected_shift_features:\n",
    "    df4[j] = df4[j].shift(-i)\n",
    "\n",
    "df4.dropna(inplace=True)\n",
    "x, y = df4.drop('target',1).copy(), df4[['datetime','target']].copy()\n",
    "\n",
    "validation = 15\n",
    "\n",
    "x_train, y_train = x[x['datetime'] < misc().get_date(0) + ' 00:00:00'], y[y['datetime'] < misc().get_date(0) + ' 00:00:00']\n",
    "\n",
    "x_train = x_train.drop(['date','datetime'],axis=1)\n",
    "y_train = y_train.drop(['datetime'], axis=1)\n",
    "\n",
    "x_train, y_train = x_train.iloc[:-validation*96,].reset_index(drop=True), y_train.iloc[:-validation*96].reset_index(drop=True)\n",
    "x_val, y_val = x_train.iloc[-validation*96:,].reset_index(drop=True), y_train.iloc[-validation*96:].reset_index(drop=True)\n",
    "\n",
    "x_train = x_train.iloc[:,1:]\n",
    "x_val = x_val.iloc[:,1:]\n",
    "y_train = y_train.iloc[:,1:]\n",
    "y_val = y_val.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_wdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
